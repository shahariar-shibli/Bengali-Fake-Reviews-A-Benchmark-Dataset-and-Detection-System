{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXj_gmCGIrPD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip3 install bnbphoneticparser\n",
        "# !pip3 install googletrans==4.0.0-rc1 \n",
        "!pip3 uninstall googletrans\n",
        "!pip3 install googletrans==3.1.0a0\n",
        "!pip3 install lingua-language-detector\n",
        "!apt update\n",
        "!apt install enchant --fix-missing\n",
        "!pip3 install pyenchant==2.0.0\n",
        "!pip3 install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcqDzoQZKUxk"
      },
      "outputs": [],
      "source": [
        "import googletrans\n",
        "from bnbphoneticparser import BanglishToBengali\n",
        "from bnbphoneticparser import BengaliToBanglish\n",
        "import time\n",
        "import string \n",
        "import re\n",
        "import enchant\n",
        "from lingua import Language, LanguageDetectorBuilder\n",
        "import emoji\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5v-VUHMIxRP"
      },
      "outputs": [],
      "source": [
        "# coding=utf-8\n",
        "translator = googletrans.Translator()\n",
        "banglish2bengali = BanglishToBengali()\n",
        "bengali2banglish = BengaliToBanglish()\n",
        "d = enchant.Dict(\"en_US\")\n",
        "languages = [Language.ENGLISH, Language.BENGALI]\n",
        "detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
        "special_characters = \"!\\\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~।\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2kORQJmRXQh"
      },
      "outputs": [],
      "source": [
        "def spaceAllocate(txt):\n",
        "  txt = str(txt)\n",
        "  text = txt.translate(str.maketrans({key: \" {0} \".format(key) for key in special_characters}))\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1HWw9QgUZKJ"
      },
      "outputs": [],
      "source": [
        "def spliteKeyWord(str):\n",
        "    regex = r\"[\\u0980-\\u09FF]+|[0-9]+|[,.।]+|[a-zA-Z]+\\'*[a-z]*\"\n",
        "    matches = re.findall(regex, str, re.UNICODE)\n",
        "    return matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWuF6n6JlB3O"
      },
      "outputs": [],
      "source": [
        "def processSplitting(lst):\n",
        "  new_lst = []\n",
        "  for wrd in lst:\n",
        "    result = spliteKeyWord(wrd)\n",
        "    if len(result) == 1:\n",
        "      new_lst.append(result[0])\n",
        "      continue\n",
        "    else:\n",
        "      for i in range(len(result)):\n",
        "        new_lst.append(result[i])\n",
        "  return new_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeGM6bOFPWvu"
      },
      "outputs": [],
      "source": [
        "def clean_txt(txt):\n",
        "  txt = txt.replace(\"\\n\", \" \")\n",
        "  txt = emoji.replace_emoji(txt)\n",
        "  bn_txt = re.split(r'[` \\=~!#@$%^&.(),\\—\\_\\-\\[\\]{};:\\'\\\\\"|<<>?]''', txt)\n",
        "  bn_txt = list(filter(lambda item: item.strip(), bn_txt))\n",
        "  return bn_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFdMb61sQcLo"
      },
      "outputs": [],
      "source": [
        "def BFRD_Translate(txt):\n",
        "  trns_txt = \"\"\n",
        "\n",
        "  txt = spaceAllocate(txt)\n",
        "  s_txt = clean_txt(txt)\n",
        "  bn_txt = processSplitting(s_txt)\n",
        "\n",
        "  for element in bn_txt:\n",
        "    if element == \"।\":\n",
        "      trns_txt = trns_txt + \" \" + element\n",
        "      continue\n",
        "    elif d.check(element):\n",
        "      #print(element)\n",
        "      if element.isdigit():\n",
        "        trns_txt = trns_txt + \" \" + translator.translate(element, src='bn', dest='bn').text\n",
        "      else:\n",
        "        trns_txt = trns_txt + \" \" + translator.translate(element, src='en', dest='bn').text\n",
        "    else:\n",
        "      if element.isdigit():\n",
        "        trns_txt = trns_txt + \" \" + translator.translate(element, src='bn', dest='bn').text\n",
        "      elif detector.detect_language_of(element) == Language.BENGALI:\n",
        "        trns_txt = trns_txt + \" \" + element\n",
        "        continue\n",
        "      else:\n",
        "        if detector.detect_language_of(element) == Language.ENGLISH:\n",
        "          trns_txt = trns_txt + \" \" + translator.translate(element, src='en', dest='bn').text\n",
        "        else:\n",
        "          trns_txt = trns_txt + \" \" + banglish2bengali.parse(element)\n",
        "    time.sleep(1)\n",
        "\n",
        "  return trns_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OUk5Gy2WdBy"
      },
      "outputs": [],
      "source": [
        "def Second_level_Translate(txt):\n",
        "    trns_txt = \"\"\n",
        "    txt = spaceAllocate(txt)\n",
        "    txt = clean_txt(txt)\n",
        "    cn_txt = processSplitting(txt)\n",
        "    #print(cn_txt)\n",
        "    for element in cn_txt:\n",
        "        if element == \"।\":\n",
        "          trns_txt = trns_txt + \" \" + element\n",
        "          continue\n",
        "        else:\n",
        "            if detector.detect_language_of(element) == Language.ENGLISH:\n",
        "               trns_txt = trns_txt + \" \" + banglish2bengali.parse(element)\n",
        "            else:\n",
        "                trns_txt = trns_txt + \" \" + element\n",
        "                continue\n",
        "    return trns_txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/fake.xlsx\")"
      ],
      "metadata": {
        "id": "88SYwiFe2UQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CTvGcDXcW8y"
      },
      "outputs": [],
      "source": [
        "result_list = []\n",
        "\n",
        "for txt in df.Review:\n",
        "  x = BFRD_Translate(txt)\n",
        "  y = Second_level_Translate(x)\n",
        "  result_list.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPVo_RzqWdB1"
      },
      "outputs": [],
      "source": [
        "new_df = pd.DataFrame()\n",
        "new_df['Translated'] = result_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B5PxXldWdB2"
      },
      "outputs": [],
      "source": [
        "new_df.to_csv('Translated_Fake.csv', encoding = 'utf-8-sig', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}